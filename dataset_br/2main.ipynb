{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import sqlalchemy as sa\n",
    "\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('main.ipynb'))))\n",
    "\n",
    "from tables import County, DataTrustedIdentifier, TrustedIdentifier\n",
    "from database import connect, create_table_if_not_exists, table_is_empty, \\\n",
    "    insert_new_identifier_trusted, find_and_replace_broken_characters, get_all_records_of_trusted_identifier, \\\n",
    "    insert_new_data_trusted_identifier, get_all_identifiers_ilike, get_all_records_with_diff_brasil, \\\n",
    "    update_country_trusted_based_original_field, has_brasil_in_country_trusted, \\\n",
    "    get_all_records_with_brasil_in_country_trusted, state_province_in_list_uf_or_list_state, update_country_trusted, \\\n",
    "    has_state_in_locality\n",
    "from sqlalchemy import and_, or_\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from unaccent import unaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 14:06:19,213 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2023-03-15 14:06:19,213 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2023-03-15 14:06:19,215 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2023-03-15 14:06:19,215 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2023-03-15 14:06:19,216 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2023-03-15 14:06:19,216 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "52606\n"
     ]
    }
   ],
   "source": [
    "session: Session\n",
    "engine, session = connect()\n",
    "engine.echo=False\n",
    "\n",
    "# directory with all 52k images\n",
    "path_fotos = '/home/xandao/Documentos/dataset_gimp/dataset-52k-sp-2021/fotos'\n",
    "list_images = [file for file in pathlib.Path(path_fotos).rglob('*') if file.is_file()]\n",
    "\n",
    "list_identified_trusted = [\n",
    "    {'full_name': 'Aline Vieira de Melo Silva', 'searched_name': ['Silva']},\n",
    "    {'full_name': 'Carmen Lúcia Falcão Ichaso', 'searched_name': ['Ichaso']},\n",
    "    {'full_name': 'Daniele Monteiro Ferreira', 'searched_name': ['Monteiro']},\n",
    "    {'full_name': 'Daniel Ruschel', 'searched_name': ['Ruschel']},\n",
    "    {'full_name': 'Elsie Franklin Guimarães', 'searched_name': ['Guimar']},\n",
    "    {'full_name': 'Eric J Tepe', 'searched_name': ['Tepe']},\n",
    "    {'full_name': 'Erika Von Sohsten de Souza Medeiros', 'searched_name': ['Medeiros']},\n",
    "    {'full_name': 'George Azevedo de Queiroz', 'searched_name': ['Queiroz']},\n",
    "    {'full_name': 'Micheline Carvalho-Silva', 'searched_name': ['Carvalho']},\n",
    "    {'full_name': 'Ricardo de la Merced Callejas Posada', 'searched_name': ['Callejas']},\n",
    "    {'full_name': 'Truman George Yuncker', 'searched_name': ['Yuncker']},\n",
    "    {'full_name': 'William Trelease', 'searched_name': ['Trelease']}\n",
    "]\n",
    "\n",
    "def text_bold(string):\n",
    "    return '\\033[1m' + string + '\\033[0m'\n",
    "\n",
    "print(len(list_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## identificadores confiaveis\n",
    "### tem que ser distinct de value_founded, por causa das identificacoes com mais de uma pessoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de identificadores confiaveis: 187\n"
     ]
    }
   ],
   "source": [
    "identifiers_trusted = session.query(TrustedIdentifier.value_founded)\\\n",
    "    .filter(TrustedIdentifier.trusted)\\\n",
    "    .distinct()\n",
    "\n",
    "print('quantidade de identificadores confiaveis: %d' % identifiers_trusted.count())\n",
    "\n",
    "create_table_if_not_exists(engine, TrustedIdentifier)\n",
    "\n",
    "if table_is_empty(session, TrustedIdentifier):\n",
    "    for identifier in list_identified_trusted:\n",
    "        for trusted_identifier in identifier['searched_name']:\n",
    "            query = get_all_identifiers_ilike(trusted_identifier, session)\n",
    "            insert_new_identifier_trusted(identifier, query, trusted_identifier, session)\n",
    "\n",
    "list_identifier_trusted = [q[0] for q in identifiers_trusted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de registros encontrados com as variacoes dos nome dos identificadores: 13182\n",
      "quantidade dados na tabela data_trusted_identifier: 13182\n"
     ]
    }
   ],
   "source": [
    "query_diff_identifier = get_all_records_of_trusted_identifier(list_identifier_trusted, session)\n",
    "\n",
    "print('quantidade de registros encontrados com as variacoes dos nome dos identificadores: %d' % query_diff_identifier.count())\n",
    "\n",
    "if table_is_empty(session, DataTrustedIdentifier):\n",
    "    insert_new_data_trusted_identifier(session, query_diff_identifier)\n",
    "\n",
    "count_data_trusted_identifier = session.query(DataTrustedIdentifier).count()\n",
    "print('quantidade dados na tabela data_trusted_identifier: %d' % count_data_trusted_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## substitui caracteres nao codificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_special_characters = [{'find': 'Ã¡', 'replace': 'á'},\n",
    "                           {'find': 'Ãº', 'replace': 'ú'},\n",
    "                           {'find': 'Ã', 'replace': 'í'},\n",
    "                           {'find': 'Ã³', 'replace': 'ó'},\n",
    "                           {'find': 'Ã±', 'replace': 'ñ'},\n",
    "                           {'find': 'Ã©', 'replace': 'é'}]\n",
    "\n",
    "for attribute in [DataTrustedIdentifier.state_province, DataTrustedIdentifier.county]:\n",
    "    for special_character in list_special_characters:\n",
    "        find_and_replace_broken_characters(attribute, session, special_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## substitui as variacoes de BR, pela palavra certa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mquantidade de registros com Brasil no campo confiavel\u001B[0m: 12144\n"
     ]
    }
   ],
   "source": [
    "list_diff_br = ['Brasil', 'BRASIL', 'Brasil/Bolivia', 'Brasilia', 'brazil', 'Brazil', 'BRazil', 'BRAZIL', '[Brésil]', 'Brésil']\n",
    "\n",
    "if has_brasil_in_country_trusted(session):\n",
    "    records_with_diff_brasil = get_all_records_with_diff_brasil(list_diff_br, session)\n",
    "    print('quantidade de registros encontrados com as variacoes dos nome dos identificadores + %s: %d' % (text_bold('variacoes de Brasil'), len(records_with_diff_brasil)))\n",
    "    update_country_trusted_based_original_field(list_diff_br, session)\n",
    "\n",
    "\n",
    "records_with_brasil_in_country_trusted = get_all_records_with_brasil_in_country_trusted(session)\n",
    "print('%s: %d' % (text_bold('quantidade de registros com Brasil no campo confiavel'), len(records_with_brasil_in_country_trusted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## adiciona BR no campo confiavel (encontra estados e cidades na tabela county, e que nao tem no campo country variacoes BR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xandao/Documentos/piperaceae-sql/database.py:184: SAWarning: Class unaccent will not make use of SQL compilation caching as it does not set the 'inherit_cache' attribute to ``True``.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this object can make use of the cache key generated by the superclass.  Alternatively, this attribute may be set to False which will disable this warning. (Background on this error at: https://sqlalche.me/e/20/cprf)\n",
      "  session.query(DataTrustedIdentifier)\\\n"
     ]
    }
   ],
   "source": [
    "county = session.query(County).distinct().all()\n",
    "\n",
    "list_uf = [unaccent(sa.func.lower(c.uf)) for c in county]\n",
    "list_state = [unaccent(sa.func.lower(c.state)) for c in county]\n",
    "list_county = [unaccent(sa.func.lower(c.county)) for c in county]\n",
    "\n",
    "update_country_trusted(list_county, list_state, list_uf, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from database import make_operation\n",
    "#\n",
    "# eq_um = unaccent(sa.func.lower(DataTrustedIdentifier.state_province))==unaccent(sa.func.lower(County.state))\n",
    "# eq_dois = unaccent(sa.func.lower(DataTrustedIdentifier.state_province))==unaccent(sa.func.lower(County.uf))\n",
    "#\n",
    "# session.query(DataTrustedIdentifier.specific_epithet, County.state).filter(or_(eq_um, eq_dois)).distinct().all()\n",
    "# make_operation(session)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# session.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Amostras do BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de registros usando somente \u001B[1mstate_province\u001B[0m: 11914\n",
      "quantidade de registros usando somente \u001B[1mstate_province e locality\u001B[0m: 11927\n"
     ]
    }
   ],
   "source": [
    "query_lower_unaccent_like = session.query(sa.func.concat('%', unaccent(sa.func.lower(County.state)), '%')).distinct().all()\n",
    "list_state_like = [q[0] for q in query_lower_unaccent_like]\n",
    "columns = [DataTrustedIdentifier.specific_epithet, DataTrustedIdentifier.barcode]\n",
    "\n",
    "query_only_state = session.query(*columns)\\\n",
    "    .filter(and_(DataTrustedIdentifier.country_trusted =='Brasil',\n",
    "                DataTrustedIdentifier.specific_epithet.is_not(None),\n",
    "                state_province_in_list_uf_or_list_state(list_state, list_uf)))\\\n",
    "    .distinct()\\\n",
    "    .all()\n",
    "\n",
    "\n",
    "query_has_state_in_locality = session.query(*columns)\\\n",
    "    .filter(and_(DataTrustedIdentifier.country_trusted=='Brasil',\n",
    "                 DataTrustedIdentifier.specific_epithet.is_not(None),\n",
    "                 or_(state_province_in_list_uf_or_list_state(list_state, list_uf),\n",
    "                     has_state_in_locality(list_state_like)\n",
    "                     )))\\\n",
    "    .distinct()\\\n",
    "    .all()\n",
    "\n",
    "print('quantidade de registros usando somente %s: %d' % (text_bold('state_province'), len(query_only_state)))\n",
    "print('quantidade de registros usando somente %s: %d' % (text_bold('state_province e locality'), len(query_has_state_in_locality)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "247"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "li = [str(l.stem) for l in list_images]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 INPA0248526\n",
      "1 INPA0248523\n",
      "2 INPA0248528\n",
      "3 NY01421575_01\n",
      "4 HUFSJ001689_v00\n",
      "5 HUFSJ001133_v00\n",
      "6 HUFSJ002198_v00\n",
      "7 HUFSJ003255_v00\n",
      "8 HVASF000487_v01\n",
      "9 INPA0019084_nd\n",
      "10 INPA0022379_nd\n",
      "11 INPA0032742_nd\n",
      "12 INPA0023115\n",
      "13 NL-U1484137\n",
      "14 INPA0012286\n",
      "15 INPA0146998\n"
     ]
    }
   ],
   "source": [
    "rm = [\"INPA0248526\", \"INPA0248523\", \"INPA0248528\", \"NY01421575_01\", \"HUFSJ001689_v00\", \"HUFSJ001133_v00\", \"HUFSJ002198_v00\", \"HUFSJ003255_v00\", \"HVASF000487_v01\", \"INPA0019084_nd\", \"INPA0022379_nd\", \"INPA0032742_nd\", \"INPA0023115\", \"NL-U1484137\", \"INPA0012286\", \"INPA0146998\"]\n",
    "\n",
    "for i, f in enumerate(rm):\n",
    "    if len([pathlib.Path('out/RGB/512/5').rglob(f + '.*')]) > 0:\n",
    "        print(i, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "10583"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = []\n",
    "for q in result:\n",
    "    for barcode in q[1]:\n",
    "        aa = list(filter(lambda x: barcode in x, li))\n",
    "        if len(aa) > 0:\n",
    "            ff.append(aa[0])\n",
    "len(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['ALCB002267', 'ALCB002268', 'ALCB002269', ..., 'VIES042095',\n       'VIES044708', 'VIES044720'], dtype='<U15')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.unique(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from images import copy_all_images\n",
    "from images import separate_images_per_threshold\n",
    "\n",
    "query = query_only_state\n",
    "# asds\n",
    "for color in ['RGB']:\n",
    "    for image_size in ['512']:\n",
    "        path_fotos = '/home/xandao/Documentos/%s/%s/w_pred_mask' % (color, image_size)\n",
    "        list_images = [file for file in pathlib.Path(path_fotos).glob('*')]\n",
    "        dst = 'out/%s/%s' % (color, image_size)\n",
    "        copy_all_images(dst, list_images, query)\n",
    "        separate_images_per_threshold(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## regioes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "total_locality = 0\n",
    "for regiao in ['Norte', 'Nordeste', 'Centro-Oeste', 'Sudeste', 'Sul']:\n",
    "    county = session.query(County)\\\n",
    "        .filter(County.regiao==regiao)\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "    list_uf = [unaccent(sa.func.lower(c.uf)) for c in county]\n",
    "    list_state = [unaccent(sa.func.lower(c.state)) for c in county]\n",
    "    list_county = [unaccent(sa.func.lower(c.county)) for c in county]\n",
    "\n",
    "    query_lower_unaccent_like = session.query(sa.func.concat('%', unaccent(sa.func.lower(County.state)), '%'))\\\n",
    "        .filter(County.regiao==regiao)\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "    list_state_like = [q[0] for q in query_lower_unaccent_like]\n",
    "    columns = [DataTrustedIdentifier.specific_epithet, DataTrustedIdentifier.barcode, DataTrustedIdentifier.country, DataTrustedIdentifier.state_province, DataTrustedIdentifier.county]\n",
    "\n",
    "    query_only_state = session.query(*columns)\\\n",
    "        .filter(and_(DataTrustedIdentifier.country_trusted =='Brasil',\n",
    "                    DataTrustedIdentifier.specific_epithet.is_not(None),\n",
    "                    state_province_in_list_uf_or_list_state(list_state, list_uf)))\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "\n",
    "    query_has_state_in_locality = session.query(*columns)\\\n",
    "        .filter(and_(DataTrustedIdentifier.country_trusted=='Brasil',\n",
    "                     DataTrustedIdentifier.specific_epithet.is_not(None),\n",
    "                     or_(state_province_in_list_uf_or_list_state(list_state, list_uf),\n",
    "                         has_state_in_locality(list_state_like)\n",
    "                         )))\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "\n",
    "\n",
    "    print('quantidade de registros usando somente %s, na regiao %s: %d' % (text_bold('state_province'), text_bold(regiao), len(query_only_state)))\n",
    "    print('quantidade de registros usando somente %s, na regiao %s: %d' % (text_bold('state_province e locality'), text_bold(regiao), len(query_has_state_in_locality)))\n",
    "    total = total + len(query_only_state)\n",
    "    total_locality = total_locality + len(query_has_state_in_locality)\n",
    "    break\n",
    "print('total sem %s: %d' % (text_bold('locality'), total))\n",
    "print('total comm %s: %d' % (text_bold('locality'), total_locality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for regiao in ['Norte', 'Nordeste', 'Centro-Oeste', 'Sudeste', 'Sul']:\n",
    "    county = session.query(County)\\\n",
    "        .filter(County.regiao==regiao)\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "    list_uf = [unaccent(sa.func.lower(c.uf)) for c in county]\n",
    "    list_state = [unaccent(sa.func.lower(c.state)) for c in county]\n",
    "    list_county = [unaccent(sa.func.lower(c.county)) for c in county]\n",
    "\n",
    "    query_lower_unaccent_like = session.query(sa.func.concat('%', unaccent(sa.func.lower(County.state)), '%'))\\\n",
    "        .filter(County.regiao==regiao)\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "    list_state_like = [q[0] for q in query_lower_unaccent_like]\n",
    "    columns = [DataTrustedIdentifier.specific_epithet, DataTrustedIdentifier.barcode, DataTrustedIdentifier.country, DataTrustedIdentifier.state_province, DataTrustedIdentifier.county]\n",
    "\n",
    "    query_only_state = session.query(*columns)\\\n",
    "        .filter(and_(DataTrustedIdentifier.country_trusted =='Brasil',\n",
    "                    DataTrustedIdentifier.specific_epithet.is_not(None),\n",
    "                    state_province_in_list_uf_or_list_state(list_state, list_uf)))\\\n",
    "        .distinct()\\\n",
    "        .all()\n",
    "\n",
    "    for color in ['RGB']:\n",
    "        for image_size in ['256']:\n",
    "            path_fotos = '/home/xandao/%s/%s/w_pred_mask' % (color, image_size)\n",
    "            list_images = list([file for file in pathlib.Path(path_fotos).glob('*.jpeg')])\n",
    "            dst = 'out2/%s/%s/%s' % (color, image_size, regiao)\n",
    "            copy_all_images(dst, list_images, query)\n",
    "            separate_images_per_threshold(dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ce972a288a646521e393254486dd3d4e40ae124f0f9a66da52dff344d61cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
